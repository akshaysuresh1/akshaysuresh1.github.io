[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nPredicting Fertilizer Input for Rice Cultivation in India\n\n\n\n\n\n\n\nData Science\n\n\nGeospatial Data Science\n\n\nSupervised Learning\n\n\nUnsupervised Learning\n\n\nAI for Agriculture\n\n\n\n\nHome to over 1.38 billion people, India is tackling a severe hunger crisis. Though the country has achieved self-sufficiency in grain production, nearly 14% of the population is still undernourished. India’s agricultural landscape is primarily rural, where widespread poverty, low literacy rates, and poor infrastructure lead to questions over its sustainability. Indiscriminate use of fertilizers…\n\n\n\n\n\n\nJun 15, 2022\n\n\nAkshay Suresh\n\n\n\n\n\n\n  \n\n\n\n\nConvolutional Neural Networks for Signal Classification in Radio Astronomy\n\n\n\n\n\n\n\nComputer Vision\n\n\nDeep Learning\n\n\nSupervised Learning\n\n\nAstronomy\n\n\n\n\nRadio waves from human technologies frequently interfere with searches for exotic astrophysical phenomena, yielding hordes of false positives in downstream signal detection pipelines. Discerning astronomical signals of interest from a pile of false positives presents a “needle in a haystack” challenge demanding significant human time investment. Implementing interference blocking at telescope…\n\n\n\n\n\n\nDec 15, 2019\n\n\nAkshay Suresh\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/2022_06_15_DSbootcamp/index.html",
    "href": "projects/2022_06_15_DSbootcamp/index.html",
    "title": "Predicting Fertilizer Input for Rice Cultivation in India",
    "section": "",
    "text": "Note\n\n\n\n\nProject team members: Akshay Suresh (lead), Arman Darbinyan, Dmitry Shcherbakov, Emilio Codecido & Leonardo Santana\nMentor: James Bramante\nGithub repo: may22-barrel\n5-minutes video presentation: YouTube link\nPresentation slides: PDF\nExecutive summary: PDF\nProgramming language: Python (numpy, pandas, scikit-learn, geopandas, matplotlib seaborn)\nSupervised machine learning (ML) techniques: Linear regression, random forest, support vector machine\nUnsupervised ML algorithms: k-means clustering, hierarchical clustering"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Research Experience\n\n\n\n\n\n10/2023 – Present\n\n\nIndependent Study & Research Upskilling\n\n\n\n\n\n\n08/2017 – 06/2023\n\n\nGraduate Researcher, Cornell University, Ithaca, NY, USA AI and Signal Processing for Automated Astrophysical Event Discovery Deep Learning Signal Processing Python Pytorch Radio Astronomy\n\n\n\n\n\n06/2022 – 08/2022\n\n\nMachine Learning Researcher, Frontier Development Lab USA Time Series Forecast of Earthquake Rates from Underground Carbon Storage Time Series Forecasting LSTM Pytorch Teamwork Climate Adaptation\n\n\n\n\n\n09/2021 – 06/2022\n\n\nVisiting Researcher, University of California, Berkeley, USA Software Development for Radar Detection from Alien Worlds [Reuters press release] [NPR Podcast] Production Code Development Python Search for Extraterrestrial Intelligence\n\n\n\n\n\n\n Technical Skills\n\n\n\n\n\nProgramming\n\n\nPython (pytorch, scikit-learn, numpy, pandas, matplotlib, seaborn, plotly), bash scripting, SQL, \\(\\LaTeX\\), HTML\n\n\n\n\n\nMachine learning\n\n\n\n\nSupervised learning:\n\n\nLinear regression, lasso & ridge regularization\n\n\nDecision trees, random forest\n\n\nSupport vector machine (SVM)\n\n\n\\(k\\)-nearest neighbors (kNN)\n\n\nConvolutional neural networks (CNN)\n\n\nRecurrent neural networks (RNN)\n\n\nLong short-term memory networks (LSTM)\n\n\n\n\nUnsupervised learning:\n\n\n\\(k\\)-means clustering\n\n\nGaussian mixture models (GMM)\n\n\n\n\nPrincipal component analysis (PCA)\n\n\nStochastic gradient descent (SGD)\n\n\nAdam optimization\n\n\n\n\n\n\n\nSoftware Engineering\n\n\nProduction code development, high performance computing (HPC)\n\n\n\n\n\nCloud Computing\n\n\nGoogle Cloud Platform (GCP), Amazon Web Services (AWS)\n\n\n\n\n\nOperating Systems\n\n\nLinux, iOS\n\n\n\n\n\nOther Software\n\n\nMicrosoft 365 Suite\n\n\n\n\n\n\n Education\n\n \n \n\n    \n        \n            \n        \n    \n        MS & PhD\n             2017 – 2023 \n        \n        \n            Major: Astronomy \n            Minor: Physics   \n        \n    \n    \n        GPA: 4.0/4.0 \n        Cranson & Edna B. Shelley Outstanding Teaching Assistant Award (2019)  \n    \n    \n\n  \n\n \n    \n        \n            \n              Indian Institute of Science Education & Research, Pune\n        \n    \n        BS & MS with Distinction\n             2012 – 2017 \n        \n        \n            Major: Physics \n            Minor: Mathematics   \n        \n    \n    \n        GPA: 9.9/10 \n        Institute Gold Medal (2017)  \n    \n\n\n\n Licenses & Certifications\n\n\n\n\n\n04/2023\n\n\nErdös Institute Data Visualization Mini-course\n\n\n\n\n\n06/2022\n\n\nErdös Institute Data Science Bootcamp\n\n\n\n\n\n\n Recreational Activities\n\nI have been an avid cricket fan since my teenage years. When possible, I attempt to experience major cricketing matches live in stadiums worldwide. Attending the World T20 final 2022 at the Melbourne Cricket Ground is most cherished cricketing memory to date.\n\n\n\n    \n    \n        \n        \n        \n        \n        \n        \n    \n    \n    \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n                        \n    \n    \n    \n    \n        \n        Previous\n    \n    \n    \n    \n        \n        Next\n    \n\n\n\nI enjoy destressing from work through board games and food. Gameistry Entertainment (Chennai, India) and Victory Point Cafe (Berkeley, CA, USA) are two personal favorite board game destinations. I maintain here a list of board games I have played since 2020. Hoping to grow this list further in the coming years!\nI love taking time out from my schedule to appreciate the Earth’s natural wonders. Witnessing the dance of the Aurora Borealis (aka the Northern Lights) in interior Alaska was a dream come true in 2022.\n\n\n\n    \n    \n        \n        \n        \n        \n        \n    \n    \n    \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n        \n        \n        \n            \n                     \n    \n    \n    \n    \n        \n        Previous\n    \n    \n    \n    \n        \n        Next"
  },
  {
    "objectID": "projects/2019_12_15_CNNclassifier/index.html#data-prep",
    "href": "projects/2019_12_15_CNNclassifier/index.html#data-prep",
    "title": "Convolutional Neural Networks for Signal Classification in Radio Astronomy",
    "section": "Data Prep",
    "text": "Data Prep\nWe generated simulated data for our study to circumvent the need to manually label thousands of real-world data chunks for supervised learning. As a first pass, we defined the following five classes for our signal classification task, including four categories of interference signals.\n\nllbb: Long-lived broadband interference + background Gaussian noise\nllnb: Long-lived narrowband interference + background Gaussian noise\nslbb: Short-lived broadband interference + background Gaussian noise\nslnb: Short-lived narrowband interference + background Gaussian noise\nnoise: Background Gaussian noise only\n\nFor each of the above classes, we simulated 1200 images of size 128 pixels \\(\\times\\) 128 pixels. From these, we randomly selected and set aside 200 images per category as validation data. The remaining images (1000 per category) formed our training dataset.\n\n\nSample frequency-time images of signals belonging to the llbb (top left), llnb (top right), slbb (bottom left) and slnb (bottom right) output classes.\n\nSince our training data are balanced across all output classes, we adopt the accuracy metric to quantify our model performance. During model training, we observed how the category-integrated model accuracy (defined below) varied with training epoch for our training and validation data. \\[\n{\\rm Network \\ accuracy \\ across \\ all \\ classes} = \\frac{\\rm No.\\  of\\  images \\\ncorrectly \\ classified}{\\rm Total \\ no. \\ of \\ images} \\times 100\\%\n\\] We also investigated confusion matrices built using category-specific model accuracies. We encourage interested readers to consult our project report for relevant details."
  },
  {
    "objectID": "projects/2019_12_15_CNNclassifier/index.html#model-architecture",
    "href": "projects/2019_12_15_CNNclassifier/index.html#model-architecture",
    "title": "Convolutional Neural Networks for Signal Classification in Radio Astronomy",
    "section": "Model Architecture",
    "text": "Model Architecture\nNeural net architectures for various applications are often arrived at through trial and error. In our study, we experimented with toy CNNs of different depths, studying their maximum achieved accuracy when optimally trained.\n\n\n\n\n\n\nNaming convention\n\n\n\nA neural network is said to be an N-layer network if it contains N layers excluding its input layer. A 1-layer network, by definition, then contains zero hidden layers between its input and output layers.\n\n\nOur base network is a 6-layer model whose hidden layers include two convolutional layers, two max-pooling layers, and one fully connected (or dense) layer. We sandwiched ReLU activation functions between our convolutional and max-pooling layers to enable our model to learn non-linear behaviors. Finally, the outputs of our flattened dense layer are normalized to probabilities using a softmax activation function.\n\n\nOur base 6-layer CNN model\n\nWe build models of greater depth by inserting additional convolutional and max-pooling layers ahead of our dense hidden layer. We refer readers to Figures 7–10 of our project report for architecture diagrams of our deeper models."
  },
  {
    "objectID": "projects/2019_12_15_CNNclassifier/index.html#model-training-results",
    "href": "projects/2019_12_15_CNNclassifier/index.html#model-training-results",
    "title": "Convolutional Neural Networks for Signal Classification in Radio Astronomy",
    "section": "Model Training & Results",
    "text": "Model Training & Results\nWe trained all of our models using the categorical cross-entropy (CE) loss function to perform multiclass classification. Further, we uniformly applied the Adam optimizer for model backpropagation with an initial learning rate of \\(10^{-5}\\).\n\n\nAccuracy curves for CNN models of different depths (various colors). Dotted and solid curves represent network performannces on the training and validation data respectively.\n\nStarting with our base network (blue curves), we notice that our model performance grows monotonically on the training data (dotted curve) with increasing epoch. However, the network accuracy on the validation data (solid curve) drops after epoch 3, suggesting that the model has now begun to overfit the training data. These trends then suggest that we need to load our saved model weights from epoch 3 to obtain robust predictions on our validation data. Note that our base model, even at epoch 3, only reaches a maximum accuracy of \\(85\\%\\) on the validation data.\nTraining CNNs of increasing depth, we observe a growth in the maximum network accuracy achieved under conditions of a robust fit. However, the incremental gain in network accuracy diminishes with every added layer. Setting a 95% accuracy threshold, we find that an 8/9-layer CNN model seems adequate for our classification problem."
  },
  {
    "objectID": "projects/2019_12_15_CNNclassifier/index.html#areas-for-improvement",
    "href": "projects/2019_12_15_CNNclassifier/index.html#areas-for-improvement",
    "title": "Convolutional Neural Networks for Signal Classification in Radio Astronomy",
    "section": "Areas for Improvement",
    "text": "Areas for Improvement\n\nOur definition of interference signal classes is overly simplistic to allow ready extension to real-world data. Interference signals in radio telescope data often exhibit complex spectrotemporal characteristics that do not fall neatly into any of our predefined output classes. For instance, consider the below sawtooth interference signal (some sort of radar?) seen in data from the Green Bank Telescope in West Viriginia, USA. \nOur models do not account for scenarios where multiple signal classes are present in a single frequency-time snippet. For instance, what if a weak astrophysical signal of interest happens to coincide in time with two bright interference signals of different bandwidths?\n\n\nPerhaps multilabel classification is worth an exercise.\nAlternatively, image segmentation routines may present a path forward."
  },
  {
    "objectID": "projects/2022_06_15_DSbootcamp/index.html#context-goal-constraints",
    "href": "projects/2022_06_15_DSbootcamp/index.html#context-goal-constraints",
    "title": "Predicting Fertilizer Input for Rice Cultivation in India",
    "section": "Context, Goal & Constraints",
    "text": "Context, Goal & Constraints\nTBD."
  },
  {
    "objectID": "projects/2022_06_15_DSbootcamp/index.html#project-workflow",
    "href": "projects/2022_06_15_DSbootcamp/index.html#project-workflow",
    "title": "Predicting Fertilizer Input for Rice Cultivation in India",
    "section": "Project Workflow",
    "text": "Project Workflow\n\n\nProject workflow diagram\n\nObjective: Predict mean NPK (nitrogen, phosophorous and potash) fertilizer inputs to achieve specific rice yields in different cultivation environments across India.\nTarget stakeholders: Agriculture policy makers in India\nData sources:\n\nDistrict-level database (1990–2016) maintained by the International Crops Research Institute for the Semi-Arid Tropics (ICRISAT):\n\nRice cultivation data: cropped area, yield, irrigated area\nSeasonality and temperature\nWater cycle data: precipitation, surface runoff, and evapotranspiration\nWind speed\nHistorical NPK fertilizer usage\n\nShapefile of Indian districts from Kaggle"
  },
  {
    "objectID": "projects/2022_06_15_DSbootcamp/index.html#modeling-and-results",
    "href": "projects/2022_06_15_DSbootcamp/index.html#modeling-and-results",
    "title": "Predicting Fertilizer Input for Rice Cultivation in India",
    "section": "Modeling and Results",
    "text": "Modeling and Results\nRice is a hardy crop capable of thriving in a variety of soils, including loams, silts, and gravel. Collating up to 26 years of district-level rice cultivation (cropped area, yield, irrigated area) and environment data (temperature, precipitation, wind speed, evapotranspiration), our analysis involved three steps.\n\nFirstly, we grouped districts with similar ecological parameters into clusters. To do so, we experimented with two unsupervised learning approaches, namely, \\(k\\)-means and hierarchical clustering. Both methods favored the grouping of Indian districts into 6 rice cultivation clusters.\n\n\n\nOptimal clustering of Indian districts based on application of hierarchical clustering to our environmental data (temperature, precipitation, wind speed, evapotranspiration). Note that the above map bears some visual resemblance to the Koppen-Geiger climate classification map of India. However, we caution readers against performing meticulous comparisons between these maps as our algorithms additionally incorporate soil-dependent features such as surface runoff and evapotranspiration.\n\n\nOver independent clusters, we regressed the historical NPK consumption data against rice yield. Here, we trialed simple linear regression, random forest regression, and support vector regression. \n\n\nResults from application of support vector regression to cluster 1 data. Our fit residuals to the potash data (bottom row) look reasonably flat and structure-free. However, the same cannot be said for our nitrogen (top row) and phosphorous (middle row) fit residuals, possibly hinting at either some confounding variable or some parameter cross-correlations unaccounted for in our analyses.\n\n\nThe symmetric mean absolute percent error (SMAPE) offers a convenient difference-based relative measure for comparing model performances across clusters with unequal number of data points.\n\n\\[\n{\\rm SMAPE} = \\left( \\frac{100\\%}{N_{\\rm observations}} \\right) \\sum_{\\rm observations} \\left(\\frac{|{\\rm True \\ value} - {\\rm Predicted \\ value}|}{(|{\\rm True \\ value}| + |{\\rm Predicted \\ value}|)/2} \\right)\n\\]\nFor a perfect model (true value = predicted value), \\({\\rm SMAPE} = 0\\%\\). Meanwhile, a null prediction (predicted value = 0) entails \\({\\rm SMAPE} = 200\\%\\).\n\nStudying the above SMAPE barplots, we note that support vector regression marginally outperforms other regression models. However, in general, our regression models are not sufficiently accurate, yielding median SMAPE values of about 50% for N and P, and nearly 75% for K."
  },
  {
    "objectID": "projects/2022_06_15_DSbootcamp/index.html#areas-for-improvement",
    "href": "projects/2022_06_15_DSbootcamp/index.html#areas-for-improvement",
    "title": "Predicting Fertilizer Input for Rice Cultivation in India",
    "section": "Areas for Improvement",
    "text": "Areas for Improvement\n\nConsider incorporating data on soil nutrient content, soil type and texture, and solar irradiance to improve the accuracy of model fits.\nAssess the impact of crop rotation and off-season farming practices on the sustainability of a desired crop yield."
  },
  {
    "objectID": "projects/2022_06_15_DSbootcamp/index.html#project-context",
    "href": "projects/2022_06_15_DSbootcamp/index.html#project-context",
    "title": "Predicting Fertilizer Input for Rice Cultivation in India",
    "section": "Project Context",
    "text": "Project Context\nThis project was completed as part of the Erdös Institute Data Science Bootcamp, Spring 2022. Within a hard 2-week deadline, team members were required to define their project goal, identify target stakeholders, and execute data analyses. The following deliverables were due at the end of the 2-week project work time.\n\n1-page executive summary\n5-minutes video presentation\nPresentation slides\nAnnotated Github repository\n\nLinks to our submitted deliverables are provided in a note near the top of this page."
  }
]